{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7c3a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28d03df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer,MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57aea576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = r'C:\\Users\\javed\\Downloads\\archive (7)\\PlantVillage'\n",
    "\n",
    "os.chdir(root_dir)\n",
    "listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b64bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of resized image\n",
    "DEFAULT_IMAGE_SIZE = tuple((256, 256))\n",
    "\n",
    "# Number of images used to train the model\n",
    "N_IMAGES = 100\n",
    "\n",
    "data_dir = os.path.join(root_dir,'train')\n",
    "\n",
    "\"\"\"We use the function `convert_image_to_array` to resize an image to the size `DEFAULT_IMAGE_SIZE` we defined above.\"\"\"\n",
    "\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "002734b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load images from all classes ...\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Load images from all classes ...\")\n",
    "plant_disease_folder_list = listdir(data_dir)\n",
    "print(len(plant_disease_folder_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f8c61f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loding Image Data ...\n",
      "Processing  Pepper__bell___Bacterial_spot ...\n",
      "Processing  Pepper__bell___healthy ...\n",
      "Processing  Potato___Early_blight ...\n",
      "Processing  Potato___healthy ...\n",
      "Processing  Potato___Late_blight ...\n",
      "Processing  Tomato_Bacterial_spot ...\n",
      "Processing  Tomato_Early_blight ...\n",
      "Processing  Tomato_healthy ...\n",
      "Processing  Tomato_Late_blight ...\n",
      "Processing  Tomato_Leaf_Mold ...\n",
      "Processing  Tomato_Septoria_leaf_spot ...\n",
      "Processing  Tomato_Spider_mites_Two_spotted_spider_mite ...\n",
      "Processing  Tomato__Target_Spot ...\n",
      "Processing  Tomato__Tomato_mosaic_virus ...\n",
      "Processing  Tomato__Tomato_YellowLeaf__Curl_Virus ...\n",
      "All the images have successfully loaded!!\n"
     ]
    }
   ],
   "source": [
    "image_list, label_list = [], []\n",
    "\n",
    "try:\n",
    "    print(\"Loding Image Data ...\")\n",
    "    for s in listdir():\n",
    "        plant_disease_folder_list = listdir(s)\n",
    "\n",
    "        for plant_disease_folder in plant_disease_folder_list:\n",
    "            print(f\"Processing  {plant_disease_folder} ...\")\n",
    "            plant_disease_image_list = listdir(f\"{data_dir}/{plant_disease_folder}/\")\n",
    "\n",
    "            for image in plant_disease_image_list[:N_IMAGES]:\n",
    "                image_directory = f\"{data_dir}/{plant_disease_folder}/{image}\"\n",
    "                if image_directory.endswith(\".jpg\")==True or image_directory.endswith(\".JPG\")==True:\n",
    "                    image_list.append(convert_image_to_array(image_directory))\n",
    "                    label_list.append(plant_disease_folder)\n",
    "\n",
    "    print(\"All the images have successfully loaded!!\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c25b091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eda9e5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 1500\n"
     ]
    }
   ],
   "source": [
    "# Transform the loaded training image data into numpy array\n",
    "np_image_list = np.array(image_list, dtype=np.float16) / 255.0\n",
    "\n",
    "# Check the number of images loaded for training\n",
    "image_len = len(image_list)\n",
    "print(f\"Total number of images: {image_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac16cff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes:  15\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Examine the labels/classes in the training dataset.\"\"\"\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "# pickle.dump(label_binarizer,open('plant_disease_label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)\n",
    "\n",
    "print(\"Total number of classes: \", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38e10ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                             height_shift_range=0.1, shear_range=0.2, \n",
    "                             zoom_range=0.2, horizontal_flip=True, \n",
    "                             fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75b8f10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully split data into TRAIN & TEST\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42)\n",
    "print('Successfully split data into TRAIN & TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6c8560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, VGG19, ResNet50, InceptionV3, MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bf4e5",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8712383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 15\n",
    "\n",
    "# Add custom top layers\n",
    "model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "for layer in model_vgg16.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01c6ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add custom top layers\n",
    "x = model_vgg16.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x) # You can adjust the number of units as needed\n",
    "x = Dropout(0.5)(x) # Optional dropout layer for regularization\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f836dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new model with custom top layers\n",
    "model_vgg16 = Model(inputs=model_vgg16.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c15e2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model_vgg16.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ac0b449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "38/38 [==============================] - 280s 7s/step - loss: 5.3047 - accuracy: 0.2750 - val_loss: 1.2992 - val_accuracy: 0.6133\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 296s 8s/step - loss: 1.1537 - accuracy: 0.6275 - val_loss: 0.8770 - val_accuracy: 0.7733\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 287s 8s/step - loss: 0.8638 - accuracy: 0.7292 - val_loss: 0.7830 - val_accuracy: 0.7567\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 283s 7s/step - loss: 0.7085 - accuracy: 0.7750 - val_loss: 0.6776 - val_accuracy: 0.7900\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 289s 8s/step - loss: 0.5277 - accuracy: 0.8358 - val_loss: 0.6655 - val_accuracy: 0.7967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15d9ce857b0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_vgg16.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ec271cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 45s 4s/step - loss: 0.6655 - accuracy: 0.7967\n",
      "Model: VGG16\n",
      "Test Accuracy: 0.79666668176651\n"
     ]
    }
   ],
   "source": [
    "test_lossVGG16, test_accVGG16 = model_vgg16.evaluate(x_test, y_test)\n",
    "print(f\"Model: VGG16\")\n",
    "print(f\"Test Accuracy: {test_accVGG16}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8ec84",
   "metadata": {},
   "source": [
    "#  Model 2: VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81584844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: VGG19\n",
    "model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3)) # Adjust input shape as needed\n",
    "for layer in model_vgg19.layers:\n",
    "    layer.trainable = False # Freeze layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8825fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Load VGG19 base\n",
    "vgg19_base = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Create a Sequential model\n",
    "model_vgg19 = Sequential()\n",
    "\n",
    "# Add the VGG19 base\n",
    "model_vgg19.add(vgg19_base)\n",
    "\n",
    "# Add custom top layers\n",
    "model_vgg19.add(Flatten())\n",
    "model_vgg19.add(Dense(256))\n",
    "model_vgg19.add(Activation('relu'))\n",
    "model_vgg19.add(Dense(15))  # 15 units for 15 classes\n",
    "model_vgg19.add(Activation('softmax'))  # Softmax activation for multi-class classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e27fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_vgg19.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9bdf809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "38/38 [==============================] - 1183s 31s/step - loss: 5.0912 - accuracy: 0.0608 - val_loss: 2.7083 - val_accuracy: 0.0500\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 1072s 28s/step - loss: 2.7083 - accuracy: 0.0667 - val_loss: 2.7088 - val_accuracy: 0.0500\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 1095s 29s/step - loss: 2.7083 - accuracy: 0.0625 - val_loss: 2.7096 - val_accuracy: 0.0500\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 1092s 29s/step - loss: 2.7080 - accuracy: 0.0708 - val_loss: 2.7099 - val_accuracy: 0.0500\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 1046s 28s/step - loss: 2.7080 - accuracy: 0.0708 - val_loss: 2.7103 - val_accuracy: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15d9e0cac80>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model_vgg19.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0625569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 108s 11s/step - loss: 2.7103 - accuracy: 0.0500\n",
      "Model: VGG19\n",
      "Test Accuracy: 0.05000000074505806\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "test_lossVGG19, test_accVGG19 = model_vgg19.evaluate(x_test, y_test)\n",
    "print(f\"Model: VGG19\")\n",
    "print(f\"Test Accuracy: {test_accVGG19}\")\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba479cd9",
   "metadata": {},
   "source": [
    "# Model 3: MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "408b8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=(256, 256, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f96fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom top layers\n",
    "model = Sequential([\n",
    "    model_mobilenet,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(15, activation='softmax')  # Adjust to match the number of classes in your dataset\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "73e4d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9acdd320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "38/38 [==============================] - 230s 6s/step - loss: 1.3026 - accuracy: 0.6083 - val_loss: 8.3132 - val_accuracy: 0.1033\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 207s 5s/step - loss: 0.3301 - accuracy: 0.9050 - val_loss: 4.6731 - val_accuracy: 0.3367\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 208s 5s/step - loss: 0.2637 - accuracy: 0.9100 - val_loss: 2.4904 - val_accuracy: 0.5500\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 206s 5s/step - loss: 0.2245 - accuracy: 0.9333 - val_loss: 3.1870 - val_accuracy: 0.5133\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 206s 5s/step - loss: 0.1761 - accuracy: 0.9475 - val_loss: 5.1954 - val_accuracy: 0.3967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15e0c965cf0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d2d29b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 1s/step - loss: 5.1954 - accuracy: 0.3967\n",
      "Model: MobileNet\n",
      "Test Accuracy: 0.39666667580604553\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Model: MobileNet\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b395a74",
   "metadata": {},
   "source": [
    "# Model 4: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c9d36499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 236s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# Model 3: ResNet50\n",
    "model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3)) # Adjust input shape as needed\n",
    "for layer in model_resnet50.layers:\n",
    "    layer.trainable = False # Freeze layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "56e642ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "\n",
    "# Load the ResNet50 model without the top layer (include_top=False)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Create a new model on top of the ResNet50 backbone\n",
    "model_resnet50_custom = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(15, activation='softmax')  # Assuming 15 classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "28637848",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model_resnet50_custom.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "30620c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "38/38 [==============================] - 739s 18s/step - loss: 1.6593 - accuracy: 0.5458 - val_loss: 3104.8162 - val_accuracy: 0.0500\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 880s 23s/step - loss: 0.6190 - accuracy: 0.7942 - val_loss: 48.3105 - val_accuracy: 0.0500\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 672s 18s/step - loss: 0.3018 - accuracy: 0.8983 - val_loss: 9.2160 - val_accuracy: 0.0633\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 569s 15s/step - loss: 0.1880 - accuracy: 0.9317 - val_loss: 33.1855 - val_accuracy: 0.0500\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 503s 13s/step - loss: 0.1271 - accuracy: 0.9575 - val_loss: 51.8762 - val_accuracy: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15e1d0ffb20>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, train and evaluate the model\n",
    "model_resnet50_custom.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "36b7c3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 22s 2s/step - loss: 51.8762 - accuracy: 0.0500\n",
      "Model: Custom ResNet50\n",
      "Test Accuracy: 0.05000000074505806\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model_resnet50_custom.evaluate(x_test, y_test)\n",
    "print(f\"Model: Custom ResNet50\") \n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(\"----------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a539e8d",
   "metadata": {},
   "source": [
    "# Model 5: InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "26d099f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: InceptionV3\n",
    "model_inceptionv3 = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3)) # Adjust input shape as needed\n",
    "for layer in model_inceptionv3.layers:\n",
    "    layer.trainable = False # Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4b952f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'num_classes' is the number of classes in your dataset\n",
    "num_classes = 15\n",
    "\n",
    "# Add custom top layers\n",
    "model5 = Sequential([\n",
    "    model_inceptionv3,  # Pre-trained layers\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Final output layer with 'num_classes' units\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55a46ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5dc2fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "38/38 [==============================] - 100s 2s/step - loss: 15.0715 - accuracy: 0.2742 - val_loss: 2.0058 - val_accuracy: 0.3833\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 87s 2s/step - loss: 1.8816 - accuracy: 0.3767 - val_loss: 1.4547 - val_accuracy: 0.5600\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 86s 2s/step - loss: 1.5835 - accuracy: 0.4900 - val_loss: 1.3267 - val_accuracy: 0.5600\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 83s 2s/step - loss: 1.3578 - accuracy: 0.5600 - val_loss: 1.2392 - val_accuracy: 0.6700\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 82s 2s/step - loss: 1.2593 - accuracy: 0.5758 - val_loss: 1.2164 - val_accuracy: 0.6133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15e42cfd690>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6b1cba73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 12s 1s/step - loss: 1.2164 - accuracy: 0.6133\n",
      "Model: InceptionV3\n",
      "Test Accuracy: 0.6133333444595337\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model5.evaluate(x_test, y_test)\n",
    "print(f\"Model: InceptionV3\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4c0c9e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javed\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_vgg16.save('plant_village_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3e6969c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.save('plant_village_InceptionV3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88aa4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
